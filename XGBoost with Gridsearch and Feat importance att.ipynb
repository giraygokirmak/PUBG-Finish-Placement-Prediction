{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c0d7f891d139c1ce5a788ec730ffb1ebd41775b0"
   },
   "source": [
    "#### First of all what is Gradient Boosting?\n",
    "##### Credits for this part goes to Sunil Ray \n",
    "Definition: The term ‘Boosting’ refers to a family of algorithms which converts weak learner to strong learners.\n",
    "\n",
    "Let’s understand this definition in detail by solving a problem of spam email identification:\n",
    "\n",
    "How would you classify an email as SPAM or not? Like everyone else, our initial approach would be to identify ‘spam’ and ‘not spam’ emails using following criteria. If:<br/>\n",
    "\n",
    "-Email has only one image file (promotional image), It’s a SPAM<br/>\n",
    "-Email has only link(s), It’s a SPAM<br/>\n",
    "-Email body consist of sentence like “You won a prize money of $ xxxxxx”, It’s a SPAM<br/>\n",
    "-Email from our official domain “Analyticsvidhya.com” , Not a SPAM<br/>\n",
    "-Email from known source, Not a SPAM<br/>\n",
    "\n",
    "Above, we’ve defined multiple rules to classify an email into ‘spam’ or ‘not spam’. But, do you think these rules individually are strong enough to successfully classify an email? No.<br/>\n",
    "\n",
    "Individually, these rules are not powerful enough to classify an email into ‘spam’ or ‘not spam’. Therefore, these rules are called as weak learner.<br/>\n",
    "\n",
    "To convert weak learner to strong learner, we’ll combine the prediction of each weak learner using methods like:\n",
    "•   Using average/ weighted average<br/>\n",
    "•   Considering prediction has higher vote<br/>\n",
    "\n",
    "For example:  Above, we have defined 5 weak learners. Out of these 5, 3 are voted as ‘SPAM’ and 2 are voted as ‘Not a SPAM’. In this case, by default, we’ll consider an email as SPAM because we have higher(3) vote for ‘SPAM’...<br/>\n",
    "For full blog post: https://www.analyticsvidhya.com/blog/2015/11/quick-introduction-boosting-algorithms-machine-learning/\n",
    "\n",
    "#### Introduction to Gradient Boost Algorithms\n",
    "##### Credits for this part goes to my fellow friend Sefik Ilkin Serengil\n",
    "It is a fact that decision tree based machine learning algorithms dominate Kaggle competitions. More than half of the winning solutions have adopted XGBoost. Recently, Microsoft announced its gradient boosting framework LightGBM. Nowadays, it steals the spotlight in gradient boosting machines. Kagglers start to use LightGBM more than XGBoost. Even though XGBoost might have higher accuracy, LightGBM runs previously 10 times and currently 6 times faster than XGBoost. Moreover, there are tens of solutions standing atop a challenge podium...<br/> (My additional note to this: There is a miracle called GPU and it gives XGBoost a boost because library natively supports gpu with only a parameter while if you need GPU boost you have to compile LightGBM for gpu usage by yourself, this situation takes away LightGBM's 6 times faster achievement because you can't even compare XGBoost with GPU parameter to LightGBM on cpu)\n",
    "For full blog post: https://sefiks.com/2018/10/13/a-gentle-introduction-to-lightgbm-for-applied-machine-learning/\n",
    "\n",
    "#### Introduction to Gridsearch\n",
    "It is in simple implementation of auto-hyperparameter tuning. scikit learn team integrated a GridsearchCV function inside of model_selection library of theirs. It exhaustively searches over specified parameter grid (multiple values for each hyperparameter) values for a given estimator. \n",
    "\n",
    "GridSearchCV implements a “fit” and a “score” method on array of hyperparameters specified in grid params set. It also implements “predict”, “predict_proba”, “decision_function”, “transform” and “inverse_transform” if they are implemented in the estimator used and returns back best_score, best_parameters that fits your data for the training. So we leave trial-error part to scikit learn. \n",
    "\n",
    "Usage is simply:\n",
    "\n",
    "from sklearn import svm, datasets<br/>\n",
    "from sklearn.model_selection import GridSearchCV<br/>\n",
    "iris = datasets.load_iris()<br/>\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}<br/>\n",
    "svc = svm.SVC(gamma=\"scale\")<br/>\n",
    "clf = GridSearchCV(svc, parameters, cv=5)<br/>\n",
    "clf.fit(iris.data, iris.target)<br/>\n",
    "sorted(clf.cv_results_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "7c2a2d316dba1e9991d64239efbd8a3223121c84"
   },
   "outputs": [],
   "source": [
    "# Import necessary everyday os libs\n",
    "import sys\n",
    "import gc\n",
    "\n",
    "# Import the usual suspects\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d36c37f23687bf6e4960b9746e8fcc3979e6edee"
   },
   "source": [
    "### Useful functions for community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1fdf37704af1b4d12bad3252572c241972888efe"
   },
   "outputs": [],
   "source": [
    "# Universal pandas dataframe memory footprint reducer for those dealing with big data but not that big that require spark\n",
    "def df_footprint_reduce(df, skip_obj=False, skip_int=False, skip_float=False, print_comparison=True):\n",
    "    '''\n",
    "    :param df              : Pandas Dataframe to shrink in memory footprint size\n",
    "    :param skip_obj        : If not desired string columns can be skipped during shrink operation\n",
    "    :param skip_int        : If not desired integer columns can be skipped during shrink operation\n",
    "    :param skip_float      : If not desired float columns can be skipped during shrink operation\n",
    "    :param print_comparison: Beware! Printing comparison needs calculation of each columns datasize\n",
    "                             so if you need speed turn this off. It's just here to show you info                            \n",
    "    :return                : Pandas Dataframe of exactly the same data and dtypes but in less memory footprint    \n",
    "    '''\n",
    "    if print_comparison:\n",
    "        print(f\"Dataframe size before shrinking column types into smallest possible: {round((sys.getsizeof(df)/1024/1024),4)} MB\")\n",
    "    for column in df.columns:\n",
    "        if (skip_obj is False) and (str(df[column].dtype)[:6] == 'object'):\n",
    "            num_unique_values = len(df[column].unique())\n",
    "            num_total_values = len(df[column])\n",
    "            if num_unique_values / num_total_values < 0.5:\n",
    "                df.loc[:,column] = df[column].astype('category')\n",
    "            else:\n",
    "                df.loc[:,column] = df[column]\n",
    "        elif (skip_int is False) and (str(df[column].dtype)[:3] == 'int'):\n",
    "            if df[column].min() > np.iinfo(np.int8).min and df[column].max() < np.iinfo(np.int8).max:\n",
    "                df[column] = df[column].astype(np.int8)\n",
    "            elif df[column].min() > np.iinfo(np.int16).min and df[column].max() < np.iinfo(np.int16).max:\n",
    "                df[column] = df[column].astype(np.int16)\n",
    "            elif df[column].min() > np.iinfo(np.int32).min and df[column].max() < np.iinfo(np.int32).max:\n",
    "                df[column] = df[column].astype(np.int32)\n",
    "        elif (skip_float is False) and (str(df[column].dtype)[:5] == 'float'):\n",
    "            if df[column].min() > np.finfo(np.float16).min and df[column].max() < np.finfo(np.float16).max:\n",
    "                df[column] = df[column].astype(np.float16)\n",
    "            elif df[column].min() > np.finfo(np.float32).min and df[column].max() < np.finfo(np.float32).max:\n",
    "                df[column] = df[column].astype(np.float32)\n",
    "    if print_comparison:\n",
    "        print(f\"Dataframe size after shrinking column types into smallest possible: {round((sys.getsizeof(df)/1024/1024),4)} MB\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e9aba5bc151434e954627191f1163bc757f74256"
   },
   "outputs": [],
   "source": [
    "# Universal pandas dataframe null/nan cleaner\n",
    "def df_null_cleaner(df, fill_with=None, drop_na=False, axis=0):\n",
    "    '''\n",
    "    Very good information on dealing with missing values of dataframes can be found at \n",
    "    http://pandas.pydata.org/pandas-docs/stable/missing_data.html\n",
    "    \n",
    "    :param df        : Pandas Dataframe to clean from missing values \n",
    "    :param fill_with : Fill missing values with a value of users choice\n",
    "    :param drop_na   : Drop either axis=0 for rows containing missing fields\n",
    "                       or axis=1 to drop columns having missing fields default rows                   \n",
    "    :return          : Pandas Dataframe cleaned from missing values \n",
    "    '''\n",
    "    df[(df == np.NINF)] = np.NaN\n",
    "    df[(df == np.Inf)] = np.NaN\n",
    "    if drop_na:\n",
    "        df.dropna(axis=axis,inplace=True)\n",
    "    if ~fill_with:\n",
    "        df.fillna(fill_with, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b1df154cb3cafaf7eb72075a94865de7d21e8aee"
   },
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "def feature_engineering(df,is_train=True):\n",
    "    if is_train:          \n",
    "        df = df[df['maxPlace'] > 1].copy()\n",
    "\n",
    "    target = 'winPlacePerc'\n",
    "    print('Grouping similar match types together')\n",
    "    df.loc[(df['matchType'] == 'solo'), 'matchType'] = 1\n",
    "    df.loc[(df['matchType'] == 'normal-solo'), 'matchType'] = 1\n",
    "    df.loc[(df['matchType'] == 'solo-fpp'), 'matchType'] = 1\n",
    "    df.loc[(df['matchType'] == 'normal-solo-fpp'), 'matchType'] = 1\n",
    "\n",
    "    df.loc[(df['matchType'] == 'duo'), 'matchType'] = 2\n",
    "    df.loc[(df['matchType'] == 'normal-duo'), 'matchType'] = 2\n",
    "    df.loc[(df['matchType'] == 'duo-fpp'), 'matchType'] = 2    \n",
    "    df.loc[(df['matchType'] == 'normal-duo-fpp'), 'matchType'] = 2\n",
    "\n",
    "    df.loc[(df['matchType'] == 'squad'), 'matchType'] = 3\n",
    "    df.loc[(df['matchType'] == 'normal-squad'), 'matchType'] = 3    \n",
    "    df.loc[(df['matchType'] == 'squad-fpp'), 'matchType'] = 3\n",
    "    df.loc[(df['matchType'] == 'normal-squad-fpp'), 'matchType'] = 3\n",
    "    \n",
    "    df.loc[(df['matchType'] == 'flaretpp'), 'matchType'] = 0\n",
    "    df.loc[(df['matchType'] == 'flarefpp'), 'matchType'] = 0\n",
    "    df.loc[(df['matchType'] == 'crashtpp'), 'matchType'] = 0\n",
    "    df.loc[(df['matchType'] == 'crashfpp'), 'matchType'] = 0\n",
    "    df.loc[(df['rankPoints'] < 0), 'rankPoints'] = 0\n",
    "    \n",
    "    print('Adding new features using existing ones')\n",
    "    df['headshotrate'] = df['kills']/df['headshotKills']\n",
    "    df['killStreakrate'] = df['killStreaks']/df['kills']\n",
    "    df['healthitems'] = df['heals'] + df['boosts']\n",
    "    df['totalDistance'] = df['rideDistance'] + df[\"walkDistance\"] + df[\"swimDistance\"]\n",
    "    df['killPlace_over_maxPlace'] = df['killPlace'] / df['maxPlace']\n",
    "    df['headshotKills_over_kills'] = df['headshotKills'] / df['kills']\n",
    "    df['distance_over_weapons'] = df['totalDistance'] / df['weaponsAcquired']\n",
    "    df['walkDistance_over_heals'] = df['walkDistance'] / df['heals']\n",
    "    df['walkDistance_over_kills'] = df['walkDistance'] / df['kills']\n",
    "    df['killsPerWalkDistance'] = df['kills'] / df['walkDistance']\n",
    "    df['skill'] = df['headshotKills'] + df['roadKills']\n",
    "    \n",
    "    print('Adding normalized features')\n",
    "    df['playersJoined'] = df.groupby('matchId')['matchId'].transform('count')\n",
    "    gc.collect()\n",
    "    df['killsNorm'] = df['kills']*((100-df['playersJoined'])/100 + 1)\n",
    "    df['damageDealtNorm'] = df['damageDealt']*((100-df['playersJoined'])/100 + 1)\n",
    "    df['maxPlaceNorm'] = df['maxPlace']*((100-df['playersJoined'])/100 + 1)\n",
    "    df['matchDurationNorm'] = df['matchDuration']*((100-df['playersJoined'])/100 + 1)\n",
    "    df['headshotKillsNorm'] = df['headshotKills']*((100-df['playersJoined'])/100 + 1)\n",
    "    df['killPlaceNorm'] = df['killPlace']*((100-df['playersJoined'])/100 + 1)\n",
    "    df['killPointsNorm'] = df['killPoints']*((100-df['playersJoined'])/100 + 1)\n",
    "    df['killStreaksNorm'] = df['killStreaks']*((100-df['playersJoined'])/100 + 1)\n",
    "    df['longestKillNorm'] = df['longestKill']*((100-df['playersJoined'])/100 + 1)\n",
    "    df['roadKillsNorm'] = df['roadKills']*((100-df['playersJoined'])/100 + 1)\n",
    "    df['teamKillsNorm'] = df['teamKills']*((100-df['playersJoined'])/100 + 1)\n",
    "    df['damageDealtNorm'] = df['damageDealt']*((100-df['playersJoined'])/100 + 1)\n",
    "    df['DBNOsNorm'] = df['DBNOs']*((100-df['playersJoined'])/100 + 1)\n",
    "    df['revivesNorm'] = df['revives']*((100-df['playersJoined'])/100 + 1)    \n",
    "    \n",
    "    # Clean null values from dataframe\n",
    "    df = df_null_cleaner(df,fill_with=0)\n",
    "\n",
    "    features = list(df.columns)\n",
    "    features.remove(\"Id\")\n",
    "    features.remove(\"matchId\")\n",
    "    features.remove(\"groupId\")\n",
    "    features.remove(\"matchType\")  \n",
    "    \n",
    "    y = pd.DataFrame()\n",
    "    if is_train: \n",
    "        print('Preparing target variable')\n",
    "        y = df.groupby(['matchId','groupId'])[target].agg('mean')\n",
    "        gc.collect()\n",
    "        features.remove(target)\n",
    "        \n",
    "    print('Aggregating means')\n",
    "    means_features = list(df.columns)\n",
    "    means_features.remove(\"Id\")\n",
    "    means_features.remove(\"matchId\")\n",
    "    means_features.remove(\"groupId\")\n",
    "    means_features.remove(\"matchType\")  \n",
    "    \n",
    "    if is_train:\n",
    "        means_features.remove(target)\n",
    "    \n",
    "    agg = df.groupby(['matchId','groupId'])[means_features].agg('mean')\n",
    "    gc.collect()\n",
    "    agg_rank = agg.groupby('matchId')[means_features].rank(pct=True).reset_index()\n",
    "    gc.collect()\n",
    "    \n",
    "    if is_train: \n",
    "        X = agg.reset_index()[['matchId','groupId']]\n",
    "    else: \n",
    "        X = df[['matchId','groupId']]\n",
    "\n",
    "    X = X.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n",
    "    X = X.merge(agg_rank, suffixes=[\"_mean\", \"_mean_rank\"], how='left', on=['matchId', 'groupId'])\n",
    "    del agg, agg_rank\n",
    "    gc.collect()\n",
    "    \n",
    "    print('Aggregating maxes')\n",
    "    maxes_features = list(df.columns) \n",
    "    maxes_features.remove(\"Id\")\n",
    "    maxes_features.remove(\"matchId\")\n",
    "    maxes_features.remove(\"groupId\")\n",
    "    maxes_features.remove(\"matchType\")  \n",
    "\n",
    "    if is_train:\n",
    "        maxes_features.remove(target)\n",
    "    \n",
    "    agg = df.groupby(['matchId','groupId'])[maxes_features].agg('max')\n",
    "    gc.collect()\n",
    "    agg_rank = agg.groupby('matchId')[maxes_features].rank(pct=True).reset_index()\n",
    "    gc.collect()\n",
    "    X = X.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n",
    "    X = X.merge(agg_rank, suffixes=[\"_max\", \"_max_rank\"], how='left', on=['matchId', 'groupId'])\n",
    "    del agg, agg_rank\n",
    "    gc.collect()\n",
    "    \n",
    "    print('Aggregating mins')\n",
    "    mins_features = list(df.columns) \n",
    "    mins_features.remove(\"Id\")\n",
    "    mins_features.remove(\"matchId\")\n",
    "    mins_features.remove(\"groupId\")\n",
    "    mins_features.remove(\"matchType\")  \n",
    "    \n",
    "    if is_train:\n",
    "        mins_features.remove(target)\n",
    "    \n",
    "    agg = df.groupby(['matchId','groupId'])[mins_features].agg('min')\n",
    "    gc.collect()\n",
    "    agg_rank = agg.groupby('matchId')[mins_features].rank(pct=True).reset_index()\n",
    "    gc.collect()\n",
    "    X = X.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n",
    "    X = X.merge(agg_rank, suffixes=[\"_min\", \"_min_rank\"], how='left', on=['matchId', 'groupId'])\n",
    "    del agg, agg_rank\n",
    "    gc.collect()\n",
    "    \n",
    "    print('Aggregating group sizes')\n",
    "    grpsize_features = list(df.columns) \n",
    "    grpsize_features.remove(\"Id\")\n",
    "    grpsize_features.remove(\"matchId\")\n",
    "    grpsize_features.remove(\"groupId\")\n",
    "    grpsize_features.remove(\"matchType\")  \n",
    "    grpsize_features.remove(\"DBNOsNorm\")\n",
    "    grpsize_features.remove(\"damageDealtNorm\")\n",
    "    grpsize_features.remove(\"headshotKillsNorm\")\n",
    "    grpsize_features.remove(\"killPlaceNorm\")\n",
    "    grpsize_features.remove(\"killPlace_over_maxPlace\")\n",
    "    grpsize_features.remove(\"killPointsNorm\")\n",
    "    grpsize_features.remove(\"killStreaksNorm\")\n",
    "    grpsize_features.remove(\"killsNorm\")\n",
    "    grpsize_features.remove(\"longestKillNorm\")\n",
    "    grpsize_features.remove(\"matchDurationNorm\")\n",
    "    grpsize_features.remove(\"matchDuration\")\n",
    "    grpsize_features.remove(\"maxPlaceNorm\")\n",
    "    grpsize_features.remove(\"maxPlace\")\n",
    "    grpsize_features.remove(\"numGroups\")\n",
    "    grpsize_features.remove(\"playersJoined\")\n",
    "    grpsize_features.remove(\"revivesNorm\")\n",
    "    grpsize_features.remove(\"roadKillsNorm\")\n",
    "    grpsize_features.remove(\"teamKillsNorm\")    \n",
    "    agg = df.groupby(['matchId','groupId'])[grpsize_features].size().reset_index(name='group_size')\n",
    "    gc.collect()\n",
    "    X = X.merge(agg, how='left', on=['matchId', 'groupId'])\n",
    "    \n",
    "    print('Aggregating match means')\n",
    "    mmeans_features = list(df.columns) \n",
    "    mmeans_features.remove(\"Id\")\n",
    "    mmeans_features.remove(\"matchId\")\n",
    "    mmeans_features.remove(\"groupId\")\n",
    "    mmeans_features.remove(\"DBNOsNorm\")\n",
    "    mmeans_features.remove(\"damageDealtNorm\")\n",
    "    mmeans_features.remove(\"headshotKillsNorm\")\n",
    "    mmeans_features.remove(\"killPlace_over_maxPlace\")\n",
    "    mmeans_features.remove(\"killPointsNorm\")\n",
    "    mmeans_features.remove(\"killStreaksNorm\")\n",
    "    mmeans_features.remove(\"longestKillNorm\")\n",
    "    mmeans_features.remove(\"matchDurationNorm\")\n",
    "    mmeans_features.remove(\"matchDuration\")\n",
    "    mmeans_features.remove(\"maxPlaceNorm\")\n",
    "    mmeans_features.remove(\"numGroups\")\n",
    "    mmeans_features.remove(\"revivesNorm\")\n",
    "    mmeans_features.remove(\"roadKillsNorm\")\n",
    "    mmeans_features.remove(\"teamKillsNorm\")      \n",
    "    agg = df.groupby(['matchId'])[mmeans_features].agg('mean').reset_index()\n",
    "    gc.collect()\n",
    "    X = X.merge(agg, suffixes=[\"\", \"_match_mean\"], how='left', on=['matchId'])\n",
    "    \n",
    "    print('Aggregating match sizes')\n",
    "    msizes_features = list(df.columns) \n",
    "    msizes_features.remove(\"Id\")\n",
    "    msizes_features.remove(\"matchId\")\n",
    "    msizes_features.remove(\"groupId\")\n",
    "    msizes_features.remove(\"DBNOsNorm\")\n",
    "    msizes_features.remove(\"damageDealtNorm\")\n",
    "    msizes_features.remove(\"headshotKillsNorm\")\n",
    "    msizes_features.remove(\"killPlace_over_maxPlace\")\n",
    "    msizes_features.remove(\"killPointsNorm\")\n",
    "    msizes_features.remove(\"killStreaksNorm\")\n",
    "    msizes_features.remove(\"longestKillNorm\")\n",
    "    msizes_features.remove(\"matchDurationNorm\")\n",
    "    msizes_features.remove(\"matchDuration\")\n",
    "    msizes_features.remove(\"maxPlaceNorm\")\n",
    "    msizes_features.remove(\"numGroups\")\n",
    "    msizes_features.remove(\"revivesNorm\")\n",
    "    msizes_features.remove(\"roadKillsNorm\")\n",
    "    msizes_features.remove(\"teamKillsNorm\")      \n",
    "    agg = df.groupby(['matchId']).size().reset_index(name='match_size')\n",
    "    gc.collect()\n",
    "    X = X.merge(agg, how='left', on=['matchId'])\n",
    "    del df, agg\n",
    "    gc.collect()\n",
    "\n",
    "    X.drop(columns = ['matchId', \n",
    "                      'groupId'\n",
    "                     ], axis=1, inplace=True)  \n",
    "    gc.collect()\n",
    "    if is_train:\n",
    "        return X, y\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "acaeafd9712a8b5946ca3bfc3d1ef2893b1d932e"
   },
   "source": [
    "### Load dataset files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "38de01e68ad32007b2bac8c56262abddff5a6e20"
   },
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('../input/train_V2.csv', engine='c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8c846d045dab5175a97f986386e49c6732ca92b1"
   },
   "outputs": [],
   "source": [
    "X_train = df_footprint_reduce(X_train, skip_obj=True)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "10342c72924553bfb9d1b1d0f725f568fab1f57a"
   },
   "outputs": [],
   "source": [
    "X_train, y_train = feature_engineering(X_train, True)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bdb60c79b454933645e22723fc4d5ea12876b0b1"
   },
   "outputs": [],
   "source": [
    "X_train = df_footprint_reduce(X_train, skip_obj=True)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b54c8286f265878278fea65d3e7f55bb608e343f"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f3be0458668ce083a809d6d906e9c5b5be3979c4"
   },
   "outputs": [],
   "source": [
    "scaler = preprocessing.MinMaxScaler(feature_range=(-1, 1), copy=False).fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5c606253d7427f0b010b85dce18d1dfca5cc85ab"
   },
   "outputs": [],
   "source": [
    "y_train = y_train * 2 - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8c5b9a1bfcfeb5882ea67ae445ae7eda36dc1949"
   },
   "source": [
    "### Test / Validation split of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7537ee715308935152af0590a07c7bdb57c21712"
   },
   "outputs": [],
   "source": [
    "# Import good old friend\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "80937f125d09cf50c76bfae76bfe8fd72a011466"
   },
   "outputs": [],
   "source": [
    "# Split dataset into train and validation set from %80 of x_train\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train, \n",
    "                                                                y_train, \n",
    "                                                                test_size=0.2)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a3e8f7484a0b24f9dbf6f67056c544a61ea93d3e"
   },
   "source": [
    "### Iinitialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cc454bf3ec6c5b51d587cae4613f6db03639f3d6"
   },
   "outputs": [],
   "source": [
    "# Import the real deal\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model with initial parameters given\n",
    "model = xgb.XGBRegressor(objective = 'reg:linear',\n",
    "                         n_estimators = 30000,\n",
    "                         metric = 'mae',\n",
    "                         bagging_fraction = 0.7,\n",
    "                         bagging_seed = 13,\n",
    "                         feature_fraction = 0.7,\n",
    "                         tree_method = 'gpu_hist',\n",
    "                         verbosity = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8141e1c21b52ef9f0c7691e7ccaef3460ff7f6aa"
   },
   "source": [
    "### Finding right hyperparameters for our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dbdfd04faf3f028d238d7a44459bcfd0540fde9b"
   },
   "outputs": [],
   "source": [
    "def find_best_hyperparameters(model):\n",
    "    # Grid parameters for using in Gridsearch while tuning\n",
    "    gridParams = {\n",
    "        'learning_rate'         : [0.1, 0.01 , 0.05],\n",
    "        'n_estimators '         : [1000, 10000, 20000],\n",
    "        'bagging_fraction'      : [0.5, 0.6 ,0.7],\n",
    "        'feature_fraction'      : [0.5, 0.6 ,0.7],\n",
    "        'num_leaves'            : [31, 80, 140]\n",
    "    }\n",
    "    # Create the grid\n",
    "    grid = GridSearchCV(model, \n",
    "                        gridParams,\n",
    "                        verbose=5,\n",
    "                        cv=3)\n",
    "    # Run the grid\n",
    "    grid.fit(X_train, y_train)\n",
    "    print('Best parameters: %s' % grid.best_params_)\n",
    "    print('Accuracy: %.2f' % grid.best_score_)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "710e076edb16a8544c0348f0af884dd3bf3d5b10",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#find_best_hyperparameters(model)   # This takes time so comment out after finding your right parameters for model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7dc38d2a385ef7a6ed3b3c81b2458d40a0ee2654"
   },
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model.fit(X_train,y_train,\n",
    "          eval_metric='mae',\n",
    "          eval_set=[(X_train, y_train), (X_validation, y_validation)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cf6016b8d52c90d82b3855bdbdb966e497a8b954"
   },
   "outputs": [],
   "source": [
    "# Competition evaluation is based on mean absolute error so we calculate it over predictions from test data labels\n",
    "print('The mean absolute error of model on validation set is:', min(model.evals_result_['validation_0']['mae']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "56b6981614c39819863038e4d44fb8707a0241d9"
   },
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7dc6d43a22fe0a1a3f694a622b2a6feb994beaed"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ax = xgb.plot_importance(model)\n",
    "fig = ax.figure\n",
    "fig.set_size_inches(20, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "64d3df607437644eaa6f662023ed9c34acfa488c"
   },
   "outputs": [],
   "source": [
    "# Clean memory and load test set\n",
    "del X_train, X_validation, y_train, y_validation \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1d17412eedf1fb70949f5748869a88103ff9a290"
   },
   "source": [
    "### Model Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6af69ac8e410d04e7b3c2d10215240b0b5340404"
   },
   "outputs": [],
   "source": [
    "test_x = pd.read_csv('../input/test_V2.csv', engine='c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6af69ac8e410d04e7b3c2d10215240b0b5340404"
   },
   "outputs": [],
   "source": [
    "test_x = df_footprint_reduce(test_x, skip_obj=True)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6af69ac8e410d04e7b3c2d10215240b0b5340404"
   },
   "outputs": [],
   "source": [
    "test_x = feature_engineering(test_x, False)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "45ad86e9cb232a5a1dd432ae63f3270af76e09a2"
   },
   "outputs": [],
   "source": [
    "scaler.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6af69ac8e410d04e7b3c2d10215240b0b5340404"
   },
   "outputs": [],
   "source": [
    "pred_test = model.predict(test_x)\n",
    "del test_x\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "92b2322f47c3f74e004e4c83413e2b6784682645"
   },
   "source": [
    "### Prepare for submission "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ac73a39852e2525dd814cc6e778bec3662e8c824"
   },
   "outputs": [],
   "source": [
    "test_set = pd.read_csv('../input/test_V2.csv', engine='c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b1fa4f2e37a750b551390f081815ef250f383793"
   },
   "outputs": [],
   "source": [
    "pred_test = pred_test.reshape(-1)\n",
    "pred_test = (pred_test + 1) / 2\n",
    "for i in range(len(test_set)):\n",
    "    winPlacePerc = pred_test[i]\n",
    "    maxPlace = int(test_set.iloc[i]['maxPlace'])\n",
    "    if maxPlace == 0:\n",
    "        winPlacePerc = 0.0\n",
    "    elif maxPlace == 1:\n",
    "        winPlacePerc = 1.0\n",
    "    else:\n",
    "        gap = 1.0 / (maxPlace - 1)\n",
    "        winPlacePerc = round(winPlacePerc / gap) * gap\n",
    "    \n",
    "    if winPlacePerc < 0: winPlacePerc = 0.0\n",
    "    if winPlacePerc > 1: winPlacePerc = 1.0    \n",
    "    pred_test[i] = winPlacePerc\n",
    "\n",
    "    if (i + 1) % 100000 == 0:\n",
    "        print(i, flush=True, end=\" \")\n",
    "\n",
    "test_set['winPlacePerc'] = pred_test\n",
    "\n",
    "submission = test_set[['Id', 'winPlacePerc']]\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fd57cc46b626cc88bc84f8490555d5d5f57f1cbe"
   },
   "source": [
    "##### Credits for some of codes used during feature engineering and post processing:\n",
    "###### https://www.kaggle.com/harshitsheoran/mlp-and-fe\n",
    "###### https://www.kaggle.com/ceshine/a-simple-post-processing-trick-lb-0237-0204"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
